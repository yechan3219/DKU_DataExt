# -*- coding: utf-8 -*-
import asyncio
import time
import html
import os
import json
import re
from typing import Dict, List, Tuple, Optional

import gradio as gr
import pyodbc  # SQL ì„œë²„ ì—°ë™ì„ ìœ„í•´ ì¶”ê°€
import pandas as pd # ì—‘ì…€ ì €ì¥ì„ ìœ„í•´ ì¶”ê°€

from crawl4ai import AsyncWebCrawler
from crawl4ai.chunking_strategy import RegexChunking

from llama import *          # LLM ê´€ë ¨ í•¨ìˆ˜ ì„í¬íŠ¸
from data import *           # ë°ì´í„° ì²˜ë¦¬ ê´€ë ¨ í•¨ìˆ˜ ì„í¬íŠ¸

# ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì • ë° ìƒì„±
SAVED_DIR = os.path.abspath(os.path.join(os.getcwd(), "saved"))
os.makedirs(SAVED_DIR, exist_ok=True)

# ====== SQL ì„œë²„ ì—°ê²° í™˜ê²½ ì„¤ì •  -> ì´ê±´ ìê¸° sql ì´ë¦„ ë„£ìœ¼ë©´ ë ë“¯ ======
DRIVER   = "ODBC Driver 17 for SQL Server"  # ë“œë¼ì´ë²„ 18 17 ë‹¤ ìˆëŠ”ë° 17ë¡œ ë˜ì„œ ì´ê±¸ë¡œ í•¨
SERVER   = "127.0.0.1"                       # ë¡œì»¬
DATABASE = "exhibition"                      # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
TABLE    = "Exhibition"                      # ì „ì‹œíšŒ ì •ë³´ í…Œì´ë¸” ì´ë¦„
SCHEMA   = "dbo"                             # ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì´ë¦„




# --------------------------------------------------------------------------------------
# SQL ì„œë²„ ì—°ê²° ë¬¸ìì—´ ìƒì„± í•¨ìˆ˜
# --------------------------------------------------------------------------------------
def make_cs_sql_login(uid: str, pw: str) -> str:
    return (
        f"DRIVER={{{DRIVER}}};"           # ODBC ë“œë¼ì´ë²„ ì§€ì •
        f"SERVER={SERVER};"               # ì„œë²„ ì£¼ì†Œ ì§€ì •
        f"DATABASE={DATABASE};"           # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ ì§€ì •
        f"UID={uid};PWD={pw};"            # ì‚¬ìš©ì IDì™€ ë¹„ë°€ë²ˆí˜¸
        "TrustServerCertificate=yes;"     # SSL ì¸ì¦ì„œ ì‹ ë¢° ì„¤ì •
    )


def _now_tag():
    """
    ì§€ê¸ˆ ì‹œê°„ íƒ€ì„ ìŠ¤íƒ¬í”„ ì°ëŠ”ê±°
    Returns: YYYYMMDD_HHMMSS ì´ë ‡ê²Œ ë‚˜ì˜´
    """
    from datetime import datetime
    return datetime.now().strftime("%Y%m%d_%H%M%S")

def _sanitize_name(name: str) -> str:
    """
    íŒŒì¼ëª…ì— ì´ìƒí•œê±° ë“¤ì–´ê°€ìˆìœ¼ë©´ ì–¸ë”ë°”ë¡œ ë°”ê¿”ì¤Œ
    """
    import re
    name = (name or "file").strip()
    name = re.sub(r"[^\w.\-]+", "_", name)  
    return name or "file"

def save_record_json_local(record, prefix: str) -> str | None:
    """
    ì¶”ì¶œëœ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ë¡œì»¬ì— ì €ì¥
    """
    try:
        if not isinstance(record, dict):
            print(f"[save_record_json_local] record is not dict: {type(record)} - {record}")
            record = {}
        
        # ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
        fname = _sanitize_name(f"{prefix}_{_now_tag()}.json")
        path = os.path.abspath(os.path.join(SAVED_DIR, fname))

        # JSON íŒŒì¼ë¡œ ì €ì¥
        with open(path, "w", encoding="utf-8") as f:
            import json
            json.dump(record, f, ensure_ascii=False, indent=2)

        # íŒŒì¼ ì €ì¥ ì„±ê³µ ì—¬ë¶€ í™•ì¸
        return path if os.path.isfile(path) else None

    except Exception as e:
        print(f"[save_record_json_local] error: {e}")
        return None

def save_merged_excel(all_results: List[Dict], prefix: str) -> str | None: # ì—‘ì…€ ì €ì¥
    try:
        if not all_results:
            print("[save_merged_excel] ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        df_list = []
        for result in all_results:
            data = []
            rec_gep = result.get('GEP', {})
            rec_myfair = result.get('Myfair', {})
            rec_auma = result.get('AUMA', {})

            # ì¶”ì¶œ í‚¤ ëª©ë¡ì— ë”°ë¼ ë°ì´í„° í–‰ ìƒì„±
            for k in EXTRACT_KEYS:
                row = {
                    "í•­ëª©": k,
                    "GEP": rec_gep.get(k, ""),
                    "Myfair": rec_myfair.get(k, ""),
                    "AUMA": rec_auma.get(k, "")
                }
                data.append(row)

            # DataFrame ìƒì„± ë° ì‹œíŠ¸ ì´ë¦„ ì§€ì •
            df = pd.DataFrame(data)
            sheet_name = _sanitize_name(result['korean_name'])[:31] # ì—‘ì…€ ì‹œíŠ¸ëª… ê¸¸ì´ ì œí•œ(31ì)
            df_list.append((sheet_name, df))

        # ì—‘ì…€ íŒŒì¼ëª… ìƒì„±
        fname = _sanitize_name(f"{prefix}_{_now_tag()}.xlsx")
        path = os.path.abspath(os.path.join(SAVED_DIR, fname))

        # ì—‘ì…€ íŒŒì¼ ìƒì„± ë° ìŠ¤íƒ€ì¼ ì ìš©
        with pd.ExcelWriter(path, engine='openpyxl') as writer:
            for sheet_name, df in df_list:
                df.to_excel(writer, sheet_name=sheet_name, index=False)

                # ì—´ ë„ˆë¹„ ìë™ ì¡°ì •
                worksheet = writer.sheets[sheet_name]
                worksheet.column_dimensions['A'].width = 25  # í•­ëª© ì—´
                worksheet.column_dimensions['B'].width = 40  # GEP ì—´
                worksheet.column_dimensions['C'].width = 40  # Myfair ì—´
                worksheet.column_dimensions['D'].width = 40  # AUMA ì—´

                # í—¤ë” ìŠ¤íƒ€ì¼ ì„¤ì •
                from openpyxl.styles import Font, PatternFill, Alignment
                header_font = Font(bold=True, color="FFFFFF")
                header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
                header_alignment = Alignment(horizontal="center", vertical="center")

                # ì²« ë²ˆì§¸ í–‰(í—¤ë”)ì— ìŠ¤íƒ€ì¼ ì ìš©
                for cell in worksheet[1]:
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = header_alignment

        return path if os.path.isfile(path) else None

    except Exception as e:
        print(f"[save_merged_excel] error: {e}")
        return None

# === ì „ì—­ CSS: í‘œ ìŠ¤íƒ€ì¼ í†µì¼ ë° ê°€ë…ì„± ê°œì„  ===
CUSTOM_CSS = """
:root{
  --ex-label-w: 170px;     /* ë¼ë²¨(ì²« ì—´) ê³ ì • ë„ˆë¹„ */
  --ex-row-h: 42px;        /* ëª¨ë“  í‘œ ê³µí†µ í–‰ ë†’ì´ */
  --ex-border: 1px solid color-mix(in oklab, var(--body-text-color) 18%, transparent);
}

/* ê²°ê³¼ í…Œì´ë¸” ê³µí†µ ìŠ¤íƒ€ì¼ */
.ex-card { padding: 2px 0; }
.ex-table { table-layout: fixed; width: 100%; border-collapse: collapse; }
.ex-table col.label { width: var(--ex-label-w); }
.ex-table th, .ex-table td {
  background: transparent !important;
  border-bottom: var(--ex-border);
  height: var(--ex-row-h);
  line-height: var(--ex-row-h);
  vertical-align: middle;
  padding: 0 10px;
  color: var(--body-text-color);
}
.ex-table th {
  font-weight: 600;
  opacity: .92;           /* ë¼ë²¨ ê°€ë…ì„± í–¥ìƒ */
}

/* ê°’ ì…€: ê¸´ í…ìŠ¤íŠ¸ëŠ” ë§ì¤„ì„í‘œ ì²˜ë¦¬, ì „ì²´ ë‚´ìš©ì€ íˆ´íŒìœ¼ë¡œ í‘œì‹œ */
.ex-table td .val {
  display: block;
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

/* ì¤„ë¬´ëŠ¬ ë°°ê²½ìœ¼ë¡œ ê°€ë…ì„± í–¥ìƒ */
.ex-table tr:nth-child(even) td {
  background: color-mix(in oklab, var(--background-fill-primary) 92%, var(--body-text-color) 8%) !important;
}

/* Gradio DataFrame í¸ì§‘í‘œì—ë„ ë™ì¼í•œ ìŠ¤íƒ€ì¼ ì ìš© */
[data-testid="dataframe"] table {
  table-layout: fixed;
}
[data-testid="dataframe"] table td,
[data-testid="dataframe"] table th {
  background: transparent !important;
  border-bottom: var(--ex-border);
  height: var(--ex-row-h);
  line-height: var(--ex-row-h);
  vertical-align: middle;
  padding: 0 10px;
  color: var(--body-text-color);
  max-width: 0;           /* ì—´ ë„ˆë¹„ ê³ ì • */
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}
"""

# --------------------------------------------------------------------------------------
# ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ë° ìƒìˆ˜
# --------------------------------------------------------------------------------------
APP_TITLE = "ë°ì¶”"  # ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª©

try:
    EXTRACT_KEYS = KEYS 
except Exception:
    EXTRACT_KEYS = [
        "ì „ì‹œíšŒ êµ­ë¬¸ëª…","ì˜ë¬¸ëª…(Full Name)","ì˜ë¬¸ëª…(ì•½ì)",
        "ê°œìµœ ì‹œì‘","ê°œìµœ ì¢…ë£Œ",
        "ê°œìµœì¥ì†Œ(êµ­ë¬¸)","ê°œìµœì¥ì†Œ(ì˜ì–´)","êµ­ê°€","ë„ì‹œ",
        "ì²« ê°œìµœë…„ë„","ê°œìµœ ì£¼ê¸°","ê³µì‹ í™ˆí˜ì´ì§€",
        "ì£¼ìµœê¸°ê´€","ë‹´ë‹¹ì","ì „í™”","ì´ë©”ì¼",
        "ì‚°ì—…ë¶„ì•¼","ì „ì‹œí’ˆëª©","ì¶œì²˜"
    ]

DATASET_COLORS = {1: "#D7263D", 2: "#1B9AAA", 3: "#2E7D32"}  # 1=AUMA(ë¹¨ê°•), 2=GEP(íŒŒë‘), 3=Myfair(ì´ˆë¡)



# --------------------------------------------------------------------------------------
# ì›¹ í¬ë¡¤ë§ ë° ë°ì´í„° ì¶”ì¶œ íŒŒì´í”„ë¼ì¸
# --------------------------------------------------------------------------------------
async def crawl_and_summarize(url: str):
    if not url:
        return "URLì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í´ë¦½ë³´ë“œì— URLì´ ë³µì‚¬ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."

    async with AsyncWebCrawler(verbose=True) as crawler:
        start_time = time.time()
        result = await crawler.arun(
            url=url,
            word_count_threshold=1,           
            chunking_strategy=RegexChunking(), 
            bypass_cache=True,                
        )
        
        raw_md = getattr(result, "markdown", "") or ""
        text_base = normalize_text(raw_md)

        record = {"markdown": text_base or "", "source_url": url}

        bytes_norm = len((text_base or "").encode("utf-8"))
        print(f"[INFO] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {bytes_norm} bytes")

        if not record:
            print("[INFO] ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        result = run_pipeline_markdown(record)

        total_time = time.time() - start_time
        print(f"[INFO] ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f} s")
        return result

async def summarize_url(url: str) -> Tuple[str, Dict[str, str]] | str:
    if not url:
        return "URLì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í´ë¦½ë³´ë“œì— URLì´ ë³µì‚¬ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."

    result = await crawl_and_summarize(url)
    if isinstance(result, str):
        return result  
        
    if result:
        rec_raw = result["data"]
        rec = canonicalize_record(rec_raw)
        
        table_md = to_markdown_table(rec)      
        pretty = to_json(rec)                 
        saved_path = save_json(result, rec, url) 

        output = (
            "### ì¶”ì¶œ ê²°ê³¼(í‘œ)\n"
            f"{table_md}\n\n"
            "### Raw JSON(ì •ë¦¬ í›„)\n"
            f"{pretty}\n"
            f"<sub>ëª¨ë¸: {result['model']} Â· ì»¨í…ìŠ¤íŠ¸: {result['num_ctx']} Â· ì¶”ì¶œì‹œê°(UTC): {result['extracted_at']}</sub>\n"
            f"**JSON ì €ì¥:** `{saved_path}`"
        )
        print("[INFO] URL ì²˜ë¦¬ ì™„ë£Œ")
        return output, rec
    else:
        return "í˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ê³  ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."



# --------------------------------------------------------------------------------------
# 3ê°œ ì „ì‹œíšŒ ì‚¬ì´íŠ¸ ê²€ìƒ‰ í•¨ìˆ˜
# --------------------------------------------------------------------------------------
def search_auma(exhibition: str) -> List[Dict[str, str]]:
    """
    AUMA ì‚¬ì´íŠ¸ì—ì„œ ì „ì‹œíšŒ ê²€ìƒ‰í•˜ì—¬ ì—¬ëŸ¬ ê²°ê³¼ ë°˜í™˜
    
    Returns:
        List[Dict[str, str]]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (display_text, url, year, month, city, country)
    """
    try:
        import time
        import re
        from selenium import webdriver
        from selenium.webdriver.common.by import By
        from selenium.webdriver.common.keys import Keys
        from selenium.webdriver.chrome.service import Service
        from webdriver_manager.chrome import ChromeDriverManager
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from selenium.common.exceptions import TimeoutException

        search_query = exhibition.strip()
        results = []
        
        options = webdriver.ChromeOptions()
        options.add_argument("--headless=new")
        options.add_argument("--window-size=1920,1080")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--start-maximized")

        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)

        try:
            driver.get("https://www.auma.de/en/")
            time.sleep(0.1)

            search_box = driver.find_element(By.ID, "searchText")
            search_box.send_keys(search_query)
            time.sleep(0.1)
            search_box.send_keys(Keys.ENTER)

            wait = WebDriverWait(driver, 20)
            wait.until(EC.presence_of_element_located((By.CLASS_NAME, "trade-fair-result")))

            row_xpath = "//tbody[@class='trade-fair-result__body']/tr[@class='trade-fair-result__row']"
            all_rows = driver.find_elements(By.XPATH, row_xpath)
            
            if not all_rows:
                print("[AUMA] no search results found")
                return []

            month_map = {
                'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,
                'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12
            }

            for i, row in enumerate(all_rows):
                try:
                    # Re-find the row to avoid stale element reference
                    current_row = driver.find_element(By.XPATH, f"({row_xpath})[{i+1}]")
                    
                    date_text = current_row.find_element(By.CLASS_NAME, "trade-fair-result__cell--strTermin").text
                    link_element = current_row.find_element(By.CLASS_NAME, "trade-fair-result__link")
                    link_text = link_element.text
                    link_href = link_element.get_attribute('href')
                    city_text = current_row.find_element(By.CLASS_NAME, "trade-fair-result__cell--strStadt").text
                    country_text = current_row.find_element(By.CLASS_NAME, "trade-fair-result__cell--strLand").text
                    
                    combined_text = f"{link_text} {city_text} {country_text}"
                    query_words = search_query.split()
                    # ìœ ì—°í•œ ê²€ìƒ‰: ê²€ìƒ‰ì–´ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ê²°ê³¼ì— í¬í•¨ (OR ì¡°ê±´)
                    title_contains_query = any(word.lower() in combined_text.lower() for word in query_words)

                    if title_contains_query:
                        # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                        year = 0
                        month = 0
                        year_match = re.search(r'(20\d{2})', date_text)
                        if year_match:
                            year = int(year_match.group(1))
                            for name, num in month_map.items():
                                if name.lower() in date_text.lower(): 
                                    month = num; break
                            if month == 0:
                                month_num_match = re.search(r'\.(\d{2})\.', date_text)
                                if month_num_match: month = int(month_num_match.group(1))

                        # í‘œì‹œ í…ìŠ¤íŠ¸ ìƒì„±
                        display_text = f"{link_text}"
                        if year:
                            display_text += f" {year}"
                        if city_text:
                            display_text += f" - {city_text}"
                        if country_text:
                            display_text += f" ({country_text})"

                        results.append({
                            'display_text': display_text,
                            'url': link_href,
                            'year': year,
                            'month': month,
                            'city': city_text,
                            'country': country_text,
                            'title': link_text
                        })
                        
                except Exception as e:
                    print(f"[AUMA] error processing row {i+1}: {e}")
                    continue

            print(f"[AUMA] found {len(results)} results")
            return results

        finally:
            driver.quit()

    except Exception as e:
        print(f"[AUMA ê²€ìƒ‰ ì˜¤ë¥˜] {e}")
        return []

def search_gep(exhibition: str) -> List[Dict[str, str]]:
    """
    GEP ì‚¬ì´íŠ¸ì—ì„œ ì „ì‹œíšŒ ê²€ìƒ‰í•˜ì—¬ ì—¬ëŸ¬ ê²°ê³¼ ë°˜í™˜
    
    Returns:
        List[Dict[str, str]]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (display_text, url, year, month, title)
    """
    try:
        import time
        import re
        from selenium import webdriver
        from selenium.webdriver.common.by import By
        from selenium.webdriver.common.keys import Keys
        from selenium.webdriver.chrome.service import Service
        from webdriver_manager.chrome import ChromeDriverManager
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from selenium.common.exceptions import TimeoutException

        search_query = exhibition.strip()
        results = []
        
        options = webdriver.ChromeOptions()
        options.add_argument("--headless=new")
        options.add_argument("--window-size=1920,1080")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--start-maximized")

        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)

        try:
            driver.get("https://www.gep.or.kr/gept/ovrss/main/mainPage.do")
            time.sleep(0.1)

            search_box = driver.find_element(By.ID, "topQuery")
            search_box.send_keys(search_query)
            time.sleep(0.1)
            search_box.send_keys(Keys.ENTER)

            wait = WebDriverWait(driver, 20)
            wait.until(EC.presence_of_element_located((By.XPATH, "//*[@id='totalSearchView']//a")))

            all_items = driver.find_elements(By.CLASS_NAME, "text-info")
            
            if not all_items:
                return []

            for item in all_items:
                try:
                    date_div = item.find_element(By.CLASS_NAME, "info-date")
                    date_text = date_div.text
                    link_element = item.find_element(By.CSS_SELECTOR, ".info-title a")
                    link_text = link_element.text
                    link_href = link_element.get_attribute('href')
                    
                    query_words = search_query.split()
                    # ìœ ì—°í•œ ê²€ìƒ‰: ê²€ìƒ‰ì–´ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ê²°ê³¼ì— í¬í•¨ (OR ì¡°ê±´)
                    title_contains_query = any(word in link_text for word in query_words)

                    if title_contains_query:
                        # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                        year = 0
                        month = 0
                        year_match = re.search(r'(20\d{2})', date_text)
                        month_match = re.search(r'-(\d{2})-', date_text)

                        if year_match and month_match:
                            year = int(year_match.group(1))
                            month = int(month_match.group(1))

                        # í‘œì‹œ í…ìŠ¤íŠ¸ ìƒì„±
                        display_text = f"{link_text}"
                        if year:
                            display_text += f" {year}"
                        if month:
                            display_text += f".{month:02d}"

                        # JavaScript ë§í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ URL ìƒì„±
                        final_url = link_href
                        if link_href and link_href.startswith("javascript:"):
                            match = re.search(r"viewOverseasExhibition\('([^']+)'\)", link_href)
                            if match:
                                exhibition_id = match.group(1)
                                final_url = f"https://www.gep.or.kr/gept/ovrss/sear/selectOverseasExhibitionView.do?exhbId={exhibition_id}"

                        results.append({
                            'display_text': display_text,
                            'url': final_url,
                            'year': year,
                            'month': month,
                            'title': link_text,
                            'original_url': link_href
                        })
                        
                except Exception as e:
                    print(f"[GEP] error processing item: {e}")
                    continue

            print(f"[GEP] found {len(results)} results")
            return results

        finally:
            driver.quit()

    except Exception as e:
        print(f"[GEP ê²€ìƒ‰ ì˜¤ë¥˜] {e}")
        return []

def search_myfair(exhibition: str) -> List[Dict[str, str]]:
    """
    Myfair ì‚¬ì´íŠ¸ì—ì„œ ì „ì‹œíšŒ ê²€ìƒ‰í•˜ì—¬ ì—¬ëŸ¬ ê²°ê³¼ ë°˜í™˜
    
    Returns:
        List[Dict[str, str]]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (display_text, url, year, month, title)
    """
    try:
        import time
        import re
        from selenium import webdriver
        from selenium.webdriver.common.by import By
        from selenium.webdriver.common.keys import Keys
        from selenium.webdriver.chrome.service import Service
        from webdriver_manager.chrome import ChromeDriverManager
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from selenium.common.exceptions import TimeoutException

        search_query = exhibition.strip()
        results = []
        
        options = webdriver.ChromeOptions()
        options.add_argument("--headless=new")
        options.add_argument("--window-size=1920,1080")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--start-maximized")

        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)

        try:
            driver.get("https://myfair.co/")
            time.sleep(0.1)

            search_box = driver.find_element(By.XPATH, "//input[@placeholder='ë°•ëŒíšŒëª… ê²€ìƒ‰']")
            search_box.send_keys(search_query)
            time.sleep(0.1)
            search_box.send_keys(Keys.ENTER)

            wait = WebDriverWait(driver, 20)
            wait.until(EC.presence_of_element_located((By.CLASS_NAME, "css-azmimp")))

            xpath_selector = "//div[@class='css-1byidqq' and .//span[@class='css-1nutr9u']]"
            all_cards = driver.find_elements(By.XPATH, xpath_selector)
            
            if not all_cards:
                print("[Myfair] no search results found")
                return []

            for card in all_cards:
                try:
                    date_span = card.find_element(By.CLASS_NAME, "css-1nutr9u")
                    date_text = date_span.text
                    link_element = card.find_element(By.XPATH, ".//a[contains(@class, 'text-md')]")
                    link_text = link_element.text
                    link_href = link_element.get_attribute('href')
                    
                    query_words = search_query.split()
                    # ìœ ì—°í•œ ê²€ìƒ‰: ê²€ìƒ‰ì–´ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ê²°ê³¼ì— í¬í•¨ (OR ì¡°ê±´)
                    title_contains_query = any(word in link_text for word in query_words)

                    if title_contains_query:
                        # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                        year = 0
                        month = 0
                        year_match = re.search(r'(20\d{2})', date_text)
                        month_match = re.search(r'(\d{1,2})ì›”', date_text)
                        
                        if year_match:
                            year = int(year_match.group(1))
                        if month_match:
                            month = int(month_match.group(1))

                        # í‘œì‹œ í…ìŠ¤íŠ¸ ìƒì„±
                        display_text = f"{link_text}"
                        if year:
                            display_text += f" {year}"
                        if month:
                            display_text += f".{month}ì›”"

                        results.append({
                            'display_text': display_text,
                            'url': link_href,
                            'year': year,
                            'month': month,
                            'title': link_text
                        })
                        
                except Exception as e:
                    print(f"[Myfair] error processing card: {e}")
                    continue

            print(f"[Myfair] found {len(results)} results")
            return results

        finally:
            driver.quit()

    except Exception as e:
        print(f"[Myfair ê²€ìƒ‰ ì˜¤ë¥˜] {e}")
        return []



# --------------------------------------------------------------------------------------
# ë‹¤ì¤‘ URL ë¹„êµ ë° ë³‘í•© ë„ìš°ë¯¸ í•¨ìˆ˜
# --------------------------------------------------------------------------------------






def _extract_multiple_parallel(urls: List[str]) -> List[Dict[str, str]]:
    """
    ì—¬ëŸ¬ URLì„ ë³‘ë ¬ë¡œ ë™ì‹œì— ì¶”ì¶œí•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ
    
    Args:
        urls (List[str]): ì¶”ì¶œí•  URL ë¦¬ìŠ¤íŠ¸
        
    Returns:
        List[Dict[str, str]]: ì¶”ì¶œëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (URL ìˆœì„œëŒ€ë¡œ)
    """
    import concurrent.futures
    import threading
    
    def extract_single(url_idx):
        url = urls[url_idx]
        if not url:
            return url_idx, {}
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            res = loop.run_until_complete(summarize_url(url))
        finally:
            loop.close()
        
        if isinstance(res, tuple) and len(res) >= 2:
            _, rec = res
            return url_idx, rec or {}
        return url_idx, {}
    
    results = [{}] * len(urls)
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        future_to_idx = {
            executor.submit(extract_single, i): i 
            for i in range(len(urls))
        }
        
        for future in concurrent.futures.as_completed(future_to_idx):
            try:
                idx, rec = future.result()
                results[idx] = rec
            except Exception as e:
                idx = future_to_idx[future]
                print(f"[ë³‘ë ¬ ì¶”ì¶œ ì˜¤ë¥˜] URL {idx+1}: {e}")
                results[idx] = {}
    
    return results



def search_three_sites_for_one(korean_name: str, english_name: str):
    """
    í•˜ë‚˜ì˜ ì „ì‹œíšŒì— ëŒ€í•´ 3ê°œ ì‚¬ì´íŠ¸ì—ì„œ ì–¸ì–´ì— ë§ì¶° ê²€ìƒ‰
    
    Args:
        korean_name (str): ì „ì‹œíšŒ êµ­ë¬¸ëª… (GEP, Myfair ê²€ìƒ‰ìš©)
        english_name (str): ì „ì‹œíšŒ ì˜ë¬¸ëª… (AUMA ê²€ìƒ‰ìš©)
        
    Returns:
        tuple: (AUMA ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, GEP ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, Myfair ê²°ê³¼ ë¦¬ìŠ¤íŠ¸)
    """
    print("-" * 50)
    print(f"[ê²€ìƒ‰ ì‹œì‘] êµ­ë¬¸: '{korean_name}', ì˜ë¬¸: '{english_name}'")

    # ê° ì‚¬ì´íŠ¸ì˜ íŠ¹ì„±ì— ë§ì¶° ê²€ìƒ‰ì–´ ì„ íƒ
    # AUMA: ë…ì¼ ì‚¬ì´íŠ¸ì´ë¯€ë¡œ ì˜ë¬¸ëª…ìœ¼ë¡œ ê²€ìƒ‰
    # GEP, Myfair: í•œêµ­ ì‚¬ì´íŠ¸ì´ë¯€ë¡œ êµ­ë¬¸ëª…ìœ¼ë¡œ ê²€ìƒ‰
    results_auma = search_auma(english_name)
    results_gep = search_gep(korean_name)
    results_myfair = search_myfair(korean_name)

    print(f"[ê²€ìƒ‰ ê²°ê³¼] AUMA: {len(results_auma)}ê°œ, GEP: {len(results_gep)}ê°œ, Myfair: {len(results_myfair)}ê°œ")
    return results_auma, results_gep, results_myfair

def render_search_results_dropdowns(results_auma: List[Dict], results_gep: List[Dict], results_myfair: List[Dict]) -> str:
    """
    3ê°œ ì‚¬ì´íŠ¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë“œë¡­ë‹¤ìš´ìœ¼ë¡œ ë Œë”ë§
    
    Args:
        results_auma: AUMA ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        results_gep: GEP ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸  
        results_myfair: Myfair ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        str: HTML ë“œë¡­ë‹¤ìš´ í‘œì‹œ
    """
    html_parts = []
    
    # AUMA ë“œë¡­ë‹¤ìš´ ->  resultë¥¼ ì‚¬ì´íŠ¸ë³„ë¡œ ì§€ì •í•´ì„œ ë“œë¡­ë‹¤ìš´ìœ¼ë¡œ êµ¬í˜„í•¨
    # ë­ ì´ì œ indexë³„ë¡œ ì§€ì •ì„ í•´ì¤¬ê³  ë“œëë‹¤ìš´ìœ¼ë¡œ êµ¬í˜„í•¨
    auma_choices = ["ì„ íƒ ì•ˆí•¨"] + [f"{i+1}. {result['display_text']}" for i, result in enumerate(results_auma)]
    auma_html = f"""
    <div style="margin: 15px 0; padding: 15px; border: 1px solid var(--border-color-primary); border-radius: 8px; background: var(--background-fill-secondary);">
        <h4 style="margin: 0 0 10px 0; color: {DATASET_COLORS.get(1, '#D7263D')}; font-size: 16px; font-weight: 600;">ğŸ” AUMA ê²€ìƒ‰ ê²°ê³¼ ({len(results_auma)}ê°œ)</h4>
        <select id="auma_dropdown" style="width: 100%; padding: 8px; border: 1px solid var(--border-color-secondary); border-radius: 4px; background: var(--background-fill-primary); color: var(--body-text-color);">
            {"".join([f'<option value="{choice}">{choice}</option>' for choice in auma_choices])}
        </select>
    </div>
    """
    html_parts.append(auma_html)
    
    # GEP ë“œë¡­ë‹¤ìš´
    gep_choices = ["ì„ íƒ ì•ˆí•¨"] + [f"{i+1}. {result['display_text']}" for i, result in enumerate(results_gep)]
    gep_html = f"""
    <div style="margin: 15px 0; padding: 15px; border: 1px solid var(--border-color-primary); border-radius: 8px; background: var(--background-fill-secondary);">
        <h4 style="margin: 0 0 10px 0; color: {DATASET_COLORS.get(2, '#1B9AAA')}; font-size: 16px; font-weight: 600;">ğŸ” GEP ê²€ìƒ‰ ê²°ê³¼ ({len(results_gep)}ê°œ)</h4>
        <select id="gep_dropdown" style="width: 100%; padding: 8px; border: 1px solid var(--border-color-secondary); border-radius: 4px; background: var(--background-fill-primary); color: var(--body-text-color);">
            {"".join([f'<option value="{choice}">{choice}</option>' for choice in gep_choices])}
        </select>
    </div>
    """
    html_parts.append(gep_html)
    
    # Myfair ë“œë¡­ë‹¤ìš´
    myfair_choices = ["ì„ íƒ ì•ˆí•¨"] + [f"{i+1}. {result['display_text']}" for i, result in enumerate(results_myfair)]
    myfair_html = f"""
    <div style="margin: 15px 0; padding: 15px; border: 1px solid var(--border-color-primary); border-radius: 8px; background: var(--background-fill-secondary);">
        <h4 style="margin: 0 0 10px 0; color: {DATASET_COLORS.get(3, '#2E7D32')}; font-size: 16px; font-weight: 600;">ğŸ” Myfair ê²€ìƒ‰ ê²°ê³¼ ({len(results_myfair)}ê°œ)</h4>
        <select id="myfair_dropdown" style="width: 100%; padding: 8px; border: 1px solid var(--border-color-secondary); border-radius: 4px; background: var(--background-fill-primary); color: var(--body-text-color);">
            {"".join([f'<option value="{choice}">{choice}</option>' for choice in myfair_choices])}
        </select>
    </div>
    """
    html_parts.append(myfair_html)
    
    # ì‹¤í–‰ ë²„íŠ¼
    execute_html = """
    <div style="margin: 20px 0; text-align: center;">
        <button id="execute_extraction" style="padding: 12px 24px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; border-radius: 6px; font-size: 16px; font-weight: 600; cursor: pointer;">
            ğŸš€ ì„ íƒëœ ì „ì‹œíšŒë¡œ ë°ì´í„° ì¶”ì¶œ ì‹¤í–‰
        </button>
    </div>
    """
    html_parts.append(execute_html)
    
    return "".join(html_parts)

def extract_selected_urls(auma_choice: str, results_auma: List[Dict], 
                         gep_choice: str, results_gep: List[Dict],
                         myfair_choice: str, results_myfair: List[Dict]) -> Tuple[str, str, str]:
    """
    ë“œë¡­ë‹¤ìš´ì—ì„œ ì„ íƒëœ ê²°ê³¼ì—ì„œ URL ì¶”ì¶œ
    
    Args:
        auma_choice: AUMA ë“œë¡­ë‹¤ìš´ ì„ íƒê°’
        results_auma: AUMA ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        gep_choice: GEP ë“œë¡­ë‹¤ìš´ ì„ íƒê°’
        results_gep: GEP ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        myfair_choice: Myfair ë“œë¡­ë‹¤ìš´ ì„ íƒê°’
        results_myfair: Myfair ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        tuple: (AUMA URL, GEP URL, Myfair URL)
    """
    def get_url_from_choice(choice: str, results: List[Dict]) -> str:
        if not choice or choice == "ì„ íƒ ì•ˆí•¨":
            return ""
        
        # ì„ íƒê°’ì—ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ (ì˜ˆ: "1. Hannover Messe 2024" -> 0)
        import re
        match = re.match(r'^(\d+)\.', choice)
        if match:
            index = int(match.group(1)) - 1
            if 0 <= index < len(results):
                return results[index]['url']
        return ""
    
    url_auma = get_url_from_choice(auma_choice, results_auma)
    url_gep = get_url_from_choice(gep_choice, results_gep)
    url_myfair = get_url_from_choice(myfair_choice, results_myfair)
    
    return url_auma, url_gep, url_myfair

def search_exhibition_in_db(search_term: str, connection=None) -> List[Dict[str, str]]:
    """
    ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì „ì‹œíšŒëª…ìœ¼ë¡œ ê²€ìƒ‰ (êµ­ë¬¸ëª…/ì˜ë¬¸ëª… ëª¨ë‘ ëŒ€ìƒ)
    
    Args:
        search_term (str): ê²€ìƒ‰ì–´
        connection: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
        
    Returns:
        List[Dict[str, str]]: ê²€ìƒ‰ëœ ì „ì‹œíšŒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    exhibitions = []
    try:
        if connection:
            conn = connection
            should_close = False
        else:
            raise Exception("ë¡œê·¸ì¸ëœ ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        cursor = conn.cursor()
        # êµ­ë¬¸ëª… ë˜ëŠ” ì˜ë¬¸ëª…ì— ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ì „ì‹œíšŒ ê²€ìƒ‰ (LIKE ì—°ì‚°ì ì‚¬ìš©)
        search_query = f"SELECT No, ExhibitionID, Industry, ExKoreanName, ExEnglishName, NameAbbreviation, HostCycle, HostType, FirstHost, OfficialSite, HostInstitution, Staff, Tel, Email, ExhibitItem, createdAt, logoImage FROM dbo.Exhibition WHERE ExKoreanName LIKE '%{search_term}%' OR ExEnglishName LIKE '%{search_term}%';"
        cursor.execute(search_query)
        rows = cursor.fetchall()
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (a.txt ê¸°ì¤€ ëª¨ë“  ì»¬ëŸ¼)
        for row in rows:
            if len(row) >= 17:
                exhibitions.append({
                    'No': str(row[0]) if row[0] else '',
                    'ExhibitionID': row[1] or '',
                    'Industry': row[2] or '',
                    'korean_name': row[3] or '',
                    'english_name': row[4] or '',
                    'NameAbbreviation': row[5] or '',
                    'host_cycle': row[6] or '',
                    'HostType': row[7] or '',
                    'first_host': str(row[8]) if row[8] else '',
                    'official_site': row[9] or '',
                    'host_institution': row[10] or '',
                    'staff': row[11] or '',
                    'tel': row[12] or '',
                    'email': row[13] or '',
                    'exhibit_item': row[14] or '',
                    'createdAt': str(row[15]) if row[15] else '',
                    'logoImage': row[16] or ''
                })
        
        return exhibitions
        
    except Exception as e:
        print(f"[DB ê²€ìƒ‰ ì˜¤ë¥˜] {e}")
        return []

def render_db_selection_table(exhibitions: List[Dict[str, str]]) -> str:
    """
    ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°„ë‹¨í•˜ê²Œ í‘œì‹œ (ì„ íƒìš©)
    
    Args:
        exhibitions (List[Dict[str, str]]): ì „ì‹œíšŒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        str: HTML í…Œì´ë¸” ë¬¸ìì—´
    """
    if not exhibitions:
        return "<div style='color: var(--body-text-color-subdued);'>ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.</div>"
    
    result_count = len(exhibitions)
    count_info = f"<div style='margin-bottom: 15px; color: var(--body-text-color); font-weight: 500;'>ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ (ì´ {result_count}ê°œ) - ì•„ë˜ì—ì„œ ì›í•˜ëŠ” ì „ì‹œíšŒë¥¼ ì„ íƒí•˜ì„¸ìš”</div>"
    
    exhibitions_html = ""
    for i, ex in enumerate(exhibitions):
        korean_name = html.escape(ex.get('korean_name', ''))
        english_name = html.escape(ex.get('english_name', ''))
        industry = html.escape(ex.get('Industry', ''))
        first_host = html.escape(ex.get('first_host', ''))
        
        # ë„ì‹œ ì •ë³´ ì¶”ì¶œ
        city = extract_city_from_exhibition(ex)
        
        # í‘œì‹œ í…ìŠ¤íŠ¸ ìƒì„±
        display_text = f"{korean_name}"
        if english_name:
            display_text += f" ({english_name})"
        if city:
            display_text += f" - {city}"
        if industry:
            display_text += f" [{industry}]"
        if first_host and first_host != 'None':
            display_text += f" (ì‹œì‘: {first_host})"
        
        # ê°„ë‹¨í•œ ì „ì‹œíšŒ ì •ë³´ í‘œì‹œ
        exhibition_html = f"""
        <div style="margin: 10px 0; padding: 12px; border: 1px solid var(--border-color-primary); border-radius: 6px; background: var(--background-fill-secondary); color: var(--body-text-color);">
            <div style="font-size: 14px; font-weight: 600; color: var(--body-text-color);">
                {i+1}. {display_text}
            </div>
        </div>
        """
        exhibitions_html += exhibition_html
    
    return count_info + exhibitions_html

def render_db_table_with_selection(exhibitions: List[Dict[str, str]]) -> str:
    """
    ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê° ì „ì‹œíšŒë³„ ì •ë³´ì™€ í•¨ê»˜ í‘œì‹œ
    
    Args:
        exhibitions (List[Dict[str, str]]): ì „ì‹œíšŒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        str: HTML í…Œì´ë¸” ë¬¸ìì—´
    """
    if not exhibitions:
        return "<div style='color: var(--body-text-color-subdued);'>ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.</div>"
    
    result_count = len(exhibitions)
    count_info = f"<div style='margin-bottom: 15px; color: var(--body-text-color); font-weight: 500;'>ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ (ì´ {result_count}ê°œ) - ì•„ë˜ì—ì„œ ì›í•˜ëŠ” ì „ì‹œíšŒë¥¼ ì„ íƒí•˜ì„¸ìš”</div>"
    
    exhibitions_html = ""
    for i, ex in enumerate(exhibitions):
        korean_name = html.escape(ex.get('korean_name', ''))
        english_name = html.escape(ex.get('english_name', ''))
        industry = html.escape(ex.get('Industry', ''))
        first_host = html.escape(ex.get('first_host', ''))
        
        # ë„ì‹œ ì •ë³´ ì¶”ì¶œ
        city = extract_city_from_exhibition(ex)
        
        # í‘œì‹œ í…ìŠ¤íŠ¸ ìƒì„±
        display_text = f"{korean_name}"
        if english_name:
            display_text += f" ({english_name})"
        if city:
            display_text += f" - {city}"
        if industry:
            display_text += f" [{industry}]"
        if first_host and first_host != 'None':
            display_text += f" (ì‹œì‘: {first_host})"
        
        # ê° ì „ì‹œíšŒë¥¼ ìœ„í•œ HTML ìƒì„± (í…Œë§ˆì— ë§ëŠ” ìƒ‰ìƒ ì‚¬ìš©)
        exhibition_html = f"""
        <div style="margin: 15px 0; padding: 15px; border: 1px solid var(--border-color-primary); border-radius: 8px; background: var(--background-fill-secondary); color: var(--body-text-color);">
            <div style="margin-bottom: 10px; font-size: 16px; font-weight: 600; color: var(--body-text-color);">
                {i+1}. {display_text}
            </div>
            <div style="margin-top: 10px; padding: 15px; background: var(--background-fill-primary); border-radius: 6px; border: 1px solid var(--border-color-secondary);">
                {render_single_exhibition_table_html(ex)}
            </div>
        </div>
        """
        exhibitions_html += exhibition_html
    
    return count_info + exhibitions_html

def render_single_exhibition_table_html(exhibition: Dict[str, str]) -> str:
    """
    ë‹¨ì¼ ì „ì‹œíšŒ ì •ë³´ë¥¼ HTML í…Œì´ë¸”ë¡œ ë Œë”ë§ (í…Œë§ˆ ì ìš©)
    
    Args:
        exhibition (Dict[str, str]): ì „ì‹œíšŒ ì •ë³´
        
    Returns:
        str: HTML í…Œì´ë¸” ë¬¸ìì—´
    """
    # ëª¨ë“  í•„ë“œ ì •ì˜ (a.txt ê¸°ì¤€)
    field_mapping = {
        'No': 'No',
        'ExhibitionID': 'ExhibitionID', 
        'Industry': 'Industry',
        'ExKoreanName': 'korean_name',
        'ExEnglishName': 'english_name',
        'NameAbbreviation': 'NameAbbreviation',
        'HostCycle': 'host_cycle',
        'HostType': 'HostType',
        'FirstHost': 'first_host',
        'OfficialSite': 'official_site',
        'HostInstitution': 'host_institution',
        'Staff': 'staff',
        'Tel': 'tel',
        'Email': 'email',
        'ExhibitItem': 'exhibit_item',
        'createdAt': 'createdAt',
        'logoImage': 'logoImage'
    }
    
    rows = ""
    for display_name, key in field_mapping.items():
        value = html.escape(exhibition.get(key, ''))
        if value:  # ê°’ì´ ìˆëŠ” ê²½ìš°ë§Œ í‘œì‹œ
            rows += (
                f"<tr>"
                f"<th style='text-align: left; padding: 8px 12px; width: 150px; font-weight: 600; color: var(--body-text-color); background: var(--background-fill-secondary); border-bottom: 1px solid var(--border-color-primary);'>{display_name}</th>"
                f"<td style='padding: 8px 12px; color: var(--body-text-color); border-bottom: 1px solid var(--border-color-primary);'><span class='val' title='{value}' style='display: block; overflow: hidden; white-space: nowrap; text-overflow: ellipsis;'>{value}</span></td>"
                f"</tr>"
            )
    
    table = (
        "<table class='ex-table' style='table-layout: fixed; width: 100%; border-collapse: collapse; border: 1px solid var(--border-color-primary); border-radius: 6px; overflow: hidden;'>"
        "<colgroup><col class='label' style='width: 150px;'><col></colgroup>"
        "<tbody>" + rows + "</tbody>"
        "</table>"
    )
    return table

def render_single_exhibition_table(exhibition: Dict[str, str]) -> str:
    """
    ë‹¨ì¼ ì „ì‹œíšŒ ì •ë³´ë¥¼ ì„¸ë¡œ í‘œë¡œ ë Œë”ë§
    
    Args:
        exhibition (Dict[str, str]): ì „ì‹œíšŒ ì •ë³´
        
    Returns:
        str: HTML í…Œì´ë¸” ë¬¸ìì—´
    """
    # ëª¨ë“  í•„ë“œ ì •ì˜ (a.txt ê¸°ì¤€)
    field_mapping = {
        'No': 'No',
        'ExhibitionID': 'ExhibitionID', 
        'Industry': 'Industry',
        'ExKoreanName': 'korean_name',
        'ExEnglishName': 'english_name',
        'NameAbbreviation': 'NameAbbreviation',
        'HostCycle': 'host_cycle',
        'HostType': 'HostType',
        'FirstHost': 'first_host',
        'OfficialSite': 'official_site',
        'HostInstitution': 'host_institution',
        'Staff': 'staff',
        'Tel': 'tel',
        'Email': 'email',
        'ExhibitItem': 'exhibit_item',
        'createdAt': 'createdAt',
        'logoImage': 'logoImage'
    }
    
    rows = []
    for display_name, key in field_mapping.items():
        value = html.escape(exhibition.get(key, ''))
        rows.append(
            f"<tr>"
            f"<th style='text-align: left; padding: 8px 12px; font-weight: 600; color: var(--body-text-color); background: var(--background-fill-secondary); border-bottom: 1px solid var(--border-color-primary);'>{display_name}</th>"
            f"<td style='padding: 8px 12px; color: var(--body-text-color); border-bottom: 1px solid var(--border-color-primary);'><span class='val' title='{value}' style='display: block; overflow: hidden; white-space: nowrap; text-overflow: ellipsis;'>{value}</span></td>"
            f"</tr>"
        )
    
    count_info = f"<div style='margin-bottom: 15px; color: var(--body-text-color); font-weight: 500;'>ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ (1ê°œ)</div>"
    
    table = (
        f"{count_info}"
        "<div class='ex-card' style='padding: 0;'>"
        "<table class='ex-table' style='table-layout: fixed; width: 100%; border-collapse: collapse; border: 1px solid var(--border-color-primary); border-radius: 6px; overflow: hidden;'>"
        "<colgroup><col class='label' style='width: 150px;'><col></colgroup>"
        "<tbody>" + "".join(rows) + "</tbody>"
        "</table></div>"
    )
    return table

def extract_city_from_exhibition(exhibition: Dict[str, str]) -> str:
    """
    ì „ì‹œíšŒ ì •ë³´ì—ì„œ ë„ì‹œ ì •ë³´ ì¶”ì¶œ
    
    Args:
        exhibition (Dict[str, str]): ì „ì‹œíšŒ ì •ë³´
        
    Returns:
        str: ë„ì‹œ ì´ë¦„
    """
    # official_siteì—ì„œ ë„ì‹œ ì •ë³´ ì¶”ì¶œ ì‹œë„
    official_site = exhibition.get('official_site', '')
    if official_site:
        import re
        # ë„ì‹œ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰
        city_keywords = ['Seoul', 'Busan', 'Incheon', 'Daegu', 'Daejeon', 'Gwangju', 'Ulsan', 'Suwon', 'Goyang', 
                        'ì„œìš¸', 'ë¶€ì‚°', 'ì¸ì²œ', 'ëŒ€êµ¬', 'ëŒ€ì „', 'ê´‘ì£¼', 'ìš¸ì‚°', 'ìˆ˜ì›', 'ê³ ì–‘',
                        'New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia',
                        'San Antonio', 'San Diego', 'Dallas', 'San Jose', 'Austin', 'Jacksonville',
                        'Frankfurt', 'Munich', 'Berlin', 'Hamburg', 'Cologne', 'DÃ¼sseldorf',
                        'Paris', 'Lyon', 'Marseille', 'Toulouse', 'Nice', 'Nantes',
                        'London', 'Birmingham', 'Manchester', 'Glasgow', 'Liverpool', 'Leeds',
                        'Tokyo', 'Osaka', 'Nagoya', 'Sapporo', 'Kobe', 'Kyoto']
        
        for city in city_keywords:
            if city.lower() in official_site.lower():
                return city
    
    # ë‹¤ë¥¸ í•„ë“œì—ì„œ ë„ì‹œ ì •ë³´ ì¶”ì¶œ ì‹œë„
    for field in ['host_institution', 'ExhibitItem']:
        text = exhibition.get(field, '')
        if text:
            for city in ['Seoul', 'Busan', 'Incheon', 'Daegu', 'Daejeon', 'Gwangju', 'Ulsan', 'Suwon', 'Goyang',
                        'ì„œìš¸', 'ë¶€ì‚°', 'ì¸ì²œ', 'ëŒ€êµ¬', 'ëŒ€ì „', 'ê´‘ì£¼', 'ìš¸ì‚°', 'ìˆ˜ì›', 'ê³ ì–‘']:
                if city in text:
                    return city
    
    return ""

def _render_site_table(site_name: str, record: Dict[str, str], color: str) -> str:
    """
    ë‹¨ì¼ ì‚¬ì´íŠ¸ ë°ì´í„°ë¥¼ í‘œë¡œ ë Œë”ë§
    
    Args:
        site_name (str): ì‚¬ì´íŠ¸ ì´ë¦„
        record (Dict[str, str]): ì¶”ì¶œëœ ë°ì´í„°
        color (str): ì‚¬ì´íŠ¸ ìƒ‰ìƒ
        
    Returns:
        str: HTML í…Œì´ë¸” ë¬¸ìì—´
    """
    if not record:
        return f"<div class='ex-card' style='padding: 15px; border: 1px solid var(--border-color-primary); border-radius: 8px; background: var(--background-fill-secondary); margin-bottom: 15px;'><h4 style='margin: 0 0 10px 0; color: {color}; font-size: 16px; font-weight: 600;'>ğŸ“Š {site_name} ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ</h4></div>"
    
    rows = []
    for k in EXTRACT_KEYS:
        value = html.escape(record.get(k, ""))
        rows.append(
            f"<tr>"
            f"<th style='text-align: left; padding: 8px 12px; font-weight: 600; color: var(--body-text-color); background: var(--background-fill-secondary); border-bottom: 1px solid var(--border-color-primary);'>{k}</th>"
            f"<td style='padding: 8px 12px; color: var(--body-text-color); border-bottom: 1px solid var(--border-color-primary);'><span class='val' title='{value}' style='display: block; overflow: hidden; white-space: nowrap; text-overflow: ellipsis;'>{value}</span></td>"
            f"</tr>"
        )
    
    table = (
        f"<div class='ex-card' style='padding: 0; margin-bottom: 15px;'>"
        f"<h4 style='margin: 0 0 15px 0; color: {color}; font-size: 18px; font-weight: 600;'>ğŸ“Š {site_name} ê²€ìƒ‰ ê²°ê³¼</h4>"
        "<table class='ex-table' style='table-layout: fixed; width: 100%; border-collapse: collapse; border: 1px solid var(--border-color-primary); border-radius: 6px; overflow: hidden;'>"
        "<colgroup><col class='label' style='width: 150px;'><col></colgroup>"
        "<tbody>" + "".join(rows) + "</tbody>"
        "</table></div>"
    )
    return table

def search_db_only(search_term: str, connection=None):
    """
    ë°ì´í„°ë² ì´ìŠ¤ì—ì„œë§Œ ì „ì‹œíšŒ ê²€ìƒ‰
    
    Args:
        search_term (str): ê²€ìƒ‰í•  ì „ì‹œíšŒ ì´ë¦„
        connection: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
        
    Returns:
        tuple: (í‘œì‹œìš© HTML, ê²€ìƒ‰ëœ ì „ì‹œíšŒ ë¦¬ìŠ¤íŠ¸) ë˜ëŠ” (ì˜¤ë¥˜ ë©”ì‹œì§€, None)
    """
    # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì „ì‹œíšŒ ê²€ìƒ‰
    exhibitions = search_exhibition_in_db(search_term, connection)
    
    # DB ì •ë³´ë§Œ í‘œì‹œ
    if exhibitions:
        db_table_html = render_db_selection_table(exhibitions)
        return db_table_html, exhibitions
    else:
        no_result_html = "<div style='color: #666; margin-bottom: 10px;'>ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ì „ì‹œíšŒê°€ ì—†ìŠµë‹ˆë‹¤.</div>"
        return no_result_html, None

def search_and_extract_single(search_term: str, connection=None):
    """
    ì „ì‹œíšŒ ê²€ìƒ‰: 1) DBì—ì„œ ë¨¼ì € ì°¾ì•„ì„œ í‘œì‹œ, 2) 3ì‚¬ì´íŠ¸ì—ì„œ ê²€ìƒ‰ ë° ë“œë¡­ë‹¤ìš´ í‘œì‹œ
    
    Args:
        search_term (str): ê²€ìƒ‰í•  ì „ì‹œíšŒ ì´ë¦„
        connection: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
        
    Returns:
        tuple: (í‘œì‹œìš© HTML, ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°) ë˜ëŠ” (ì˜¤ë¥˜ ë©”ì‹œì§€, None)
    """
    # 1. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì „ì‹œíšŒ ê²€ìƒ‰
    exhibitions = search_exhibition_in_db(search_term, connection)
    
    # DB ì •ë³´ í‘œì‹œ
    db_table_html = render_db_selection_table(exhibitions) if exhibitions else "<div style='color: #666; margin-bottom: 10px;'>ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ì „ì‹œíšŒê°€ ì—†ìŠµë‹ˆë‹¤.</div>"
    
    # 2. 3ì‚¬ì´íŠ¸ ê²€ìƒ‰ (DB ê²°ê³¼ì™€ ìƒê´€ì—†ì´ í•­ìƒ ì‹¤í–‰)
    if exhibitions:
        # DBì— ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°: ì²« ë²ˆì§¸ ê²°ê³¼ë¡œ ê²€ìƒ‰
        ex = exhibitions[0]
        korean_name = ex['korean_name']
        english_name = ex['english_name']
        print(f"[DB ê²€ìƒ‰ ì„±ê³µ] '{korean_name}' ì°¾ìŒ. 3ì‚¬ì´íŠ¸ ê²€ìƒ‰ ì‹œì‘...")
        results_auma, results_gep, results_myfair = search_three_sites_for_one(korean_name, english_name)
    else:
        # DBì— ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°: ê²€ìƒ‰ì–´ë¡œ ì§ì ‘ ê²€ìƒ‰
        print(f"[DB ê²€ìƒ‰ ì‹¤íŒ¨] '{search_term}' ì—†ìŒ. 3ì‚¬ì´íŠ¸ ì§ì ‘ ê²€ìƒ‰ ì‹œì‘...")
        results_auma = search_auma(search_term)
        results_gep = search_gep(search_term)
        results_myfair = search_myfair(search_term)
    
    # 3. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë“œë¡­ë‹¤ìš´ìœ¼ë¡œ í‘œì‹œ
    dropdowns_html = render_search_results_dropdowns(results_auma, results_gep, results_myfair)
    
    # DB ì •ë³´ì™€ ë“œë¡­ë‹¤ìš´ ê²°í•©
    final_html = db_table_html + "<hr>" + dropdowns_html
    
    # ì €ì¥ìš© ë°ì´í„° êµ¬ì¡°í™” (ì„ íƒëœ ê²°ê³¼ëŠ” ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸ë¨)
    result_data = {
        "korean_name": exhibitions[0]['korean_name'] if exhibitions else search_term,
        "english_name": exhibitions[0]['english_name'] if exhibitions else search_term,
        "AUMA": {},
        "GEP": {},
        "Myfair": {},
        "db_results": exhibitions,
        "search_results": {
            "auma": results_auma,
            "gep": results_gep,
            "myfair": results_myfair
        }
    }
    
    return final_html, result_data

def extract_from_selected_choices(auma_choice: str, gep_choice: str, myfair_choice: str, search_data: Dict):
    """
    ì‚¬ìš©ìê°€ ì„ íƒí•œ ë“œë¡­ë‹¤ìš´ í•­ëª©ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ
    
    Args:
        auma_choice: AUMA ë“œë¡­ë‹¤ìš´ ì„ íƒê°’
        gep_choice: GEP ë“œë¡­ë‹¤ìš´ ì„ íƒê°’
        myfair_choice: Myfair ë“œë¡­ë‹¤ìš´ ì„ íƒê°’
        search_data: ì´ì „ ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°
        
    Returns:
        tuple: (í‘œì‹œìš© HTML, ê²°ê³¼ ë°ì´í„°)
    """
    if not search_data or 'search_results' not in search_data:
        return "ê²€ìƒ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", None
    
    results_auma = search_data['search_results'].get('auma', [])
    results_gep = search_data['search_results'].get('gep', [])
    results_myfair = search_data['search_results'].get('myfair', [])
    
    # ì„ íƒëœ URL ì¶”ì¶œ
    url_auma, url_gep, url_myfair = extract_selected_urls(
        auma_choice, results_auma, gep_choice, results_gep, myfair_choice, results_myfair
    )
    
    urls = [url_auma, url_gep, url_myfair]
    
    # ì„ íƒëœ URLë“¤ì—ì„œ ë³‘ë ¬ë¡œ ì •ë³´ ì¶”ì¶œ
    records = _extract_multiple_parallel(urls)
    rec_auma, rec_gep, rec_myfair = records
    
    # ê° ì‚¬ì´íŠ¸ ê²°ê³¼ë¥¼ ê°œë³„ í‘œë¡œ ìƒì„±
    auma_html = _render_site_table("AUMA", rec_auma, DATASET_COLORS.get(1, "#D7263D"))
    gep_html = _render_site_table("GEP", rec_gep, DATASET_COLORS.get(2, "#1B9AAA"))
    myfair_html = _render_site_table("Myfair", rec_myfair, DATASET_COLORS.get(3, "#2E7D32"))
    
    # ê²°ê³¼ ê²°í•©
    final_html = auma_html + gep_html + myfair_html
    
    # ì €ì¥ìš© ë°ì´í„° ì—…ë°ì´íŠ¸
    result_data = search_data.copy()
    result_data.update({
        "AUMA": rec_auma,
        "GEP": rec_gep,
        "Myfair": rec_myfair
    })
    
    return final_html, result_data

def process_selected_exhibition(selected_index: float, exhibitions_list: List[Dict], enable_search: bool, connection=None):
    """
    ì„ íƒëœ ì „ì‹œíšŒë¥¼ ì²˜ë¦¬í•˜ì—¬ ìƒì„¸ ì •ë³´ í‘œì‹œ ë˜ëŠ” ì „ì²´ ê²€ìƒ‰/ì¶”ì¶œ ìˆ˜í–‰
    
    Args:
        selected_index (float): ì„ íƒëœ ì „ì‹œíšŒ ì¸ë±ìŠ¤
        exhibitions_list (List[Dict]): ê²€ìƒ‰ëœ ì „ì‹œíšŒ ë¦¬ìŠ¤íŠ¸
        enable_search (bool): ê²€ìƒ‰ê¸°ëŠ¥ í™œì„±í™” ì—¬ë¶€
        connection: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
        
    Returns:
        tuple: (ìƒì„¸ ì •ë³´ HTML, ì „ì²´ ê²°ê³¼ HTML, ì €ì¥ ë°ì´í„°) ë˜ëŠ” (ì˜¤ë¥˜ ë©”ì‹œì§€, None, None)
    """
    if selected_index is None or not exhibitions_list or selected_index >= len(exhibitions_list):
        return "ì„ íƒëœ ì „ì‹œíšŒê°€ ì—†ìŠµë‹ˆë‹¤.", None, None
    
    # ì„ íƒëœ ì „ì‹œíšŒ ì •ë³´
    selected_exhibition = exhibitions_list[int(selected_index)]
    korean_name = selected_exhibition['korean_name']
    english_name = selected_exhibition['english_name']
    
    # ìƒì„¸ ì •ë³´ í‘œì‹œ
    details_html = render_single_exhibition_table(selected_exhibition)
    
    if not enable_search:
        # ê²€ìƒ‰ê¸°ëŠ¥ ë¹„í™œì„±í™”: ìƒì„¸ ì •ë³´ë§Œ í‘œì‹œ
        result_data = {
            "korean_name": korean_name,
            "english_name": english_name,
            "AUMA": {},
            "GEP": {},
            "Myfair": {},
            "db_results": [selected_exhibition]
        }
        return details_html, None, result_data
    else:
        # ê²€ìƒ‰ê¸°ëŠ¥ í™œì„±í™”: 3ì‚¬ì´íŠ¸ ê²€ìƒ‰ ë° ì¶”ì¶œ
        print(f"[ì„ íƒëœ ì „ì‹œíšŒ] '{korean_name}' 3ì‚¬ì´íŠ¸ ê²€ìƒ‰ ì‹œì‘...")
        url_auma, url_gep, url_myfair = search_three_sites_for_one(korean_name, english_name)
        urls = [url_auma, url_gep, url_myfair]
        
        # ë³‘ë ¬ë¡œ ì •ë³´ ì¶”ì¶œ
        records = _extract_multiple_parallel(urls)
        rec_auma, rec_gep, rec_myfair = records
        
        # ê° ì‚¬ì´íŠ¸ ê²°ê³¼ë¥¼ ê°œë³„ í‘œë¡œ ìƒì„±
        auma_html = _render_site_table("AUMA", rec_auma, DATASET_COLORS.get(1, "#D7263D"))
        gep_html = _render_site_table("GEP", rec_gep, DATASET_COLORS.get(2, "#1B9AAA"))
        myfair_html = _render_site_table("Myfair", rec_myfair, DATASET_COLORS.get(3, "#2E7D32"))
        
        # ìƒì„¸ ì •ë³´ì™€ 3ì‚¬ì´íŠ¸ ì •ë³´ ê²°í•©
        final_html = details_html + "<hr>" + auma_html + gep_html + myfair_html
        
        result_data = {
            "korean_name": korean_name,
            "english_name": english_name,
            "AUMA": rec_auma,
            "GEP": rec_gep,
            "Myfair": rec_myfair,
            "db_results": [selected_exhibition]
        }
        
        return details_html, final_html, result_data







# --------------------------------------------------------------------------------------
# ë¡œê·¸ì¸ ìƒíƒœ ê´€ë¦¬ í•¨ìˆ˜
# --------------------------------------------------------------------------------------



def try_login(uid: str, pw: str, state):
    """
    SQL ì„œë²„ ë¡œê·¸ì¸ ì‹œë„ ë° ìƒíƒœ ê´€ë¦¬, ì—†ëŠ”ê±¸ë¡œ í•˜ë©´ ì „ë¶€ ì˜¤ë¥˜ ëœ¸
    
    Args:
        uid (str): ì‚¬ìš©ì ID
        pw (str): ë¹„ë°€ë²ˆí˜¸
        state: í˜„ì¬ ë¡œê·¸ì¸ ìƒíƒœ
        
    Returns:
        tuple: (ë¡œê·¸ì¸ ì„¹ì…˜ ê°€ì‹œì„±, ì˜¤ë¥˜ ë©”ì‹œì§€, ì—…ë°ì´íŠ¸ëœ ìƒíƒœ)
    """
    if not uid or not pw:
        return gr.update(visible=True), gr.update(value="IDì™€ PWë¥¼ ì…ë ¥í•˜ì„¸ìš”.", visible=True), state
    
    try:
        # SQL Server ì—°ê²° ë¬¸ìì—´ ìƒì„± ë° ì ‘ì† ì‹œë„
        cs = make_cs_sql_login(uid, pw)
        conn = pyodbc.connect(cs)
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ì¿¼ë¦¬ ì‹¤í–‰
        cursor = conn.cursor()
        cursor.execute("SELECT 1")
        test_result = cursor.fetchone()
        
        # ë¡œê·¸ì¸ ì„±ê³µ ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸
        new_state = {"logged_in": True, "connection": conn}
        return gr.update(visible=False), gr.update(value="ë¡œê·¸ì¸ ì„±ê³µ!", visible=False), new_state
        
    except Exception as e:
        # ë¡œê·¸ì¸ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
        error_msg = f"ë¡œê·¸ì¸ ì‹¤íŒ¨: {str(e)}"
        return gr.update(visible=True), gr.update(value=error_msg, visible=True), state

# --------------------------------------------------------------------------------------
# Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±
# --------------------------------------------------------------------------------------

with gr.Blocks(css=CUSTOM_CSS) as demo:
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ì¸ ìƒíƒœ ê´€ë¦¬
    login_state = gr.State({"logged_in": False, "connection": None})
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª© í‘œì‹œ
    gr.Markdown(f"# {APP_TITLE}")
    
    # ë¡œê·¸ì¸ ìƒíƒœ í‘œì‹œ ì˜ì—­
    login_status = gr.Markdown("### ğŸ”’ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤")
    
    # ë¡œê·¸ì¸ í¼ ì„¹ì…˜
    with gr.Group(visible=True) as login_section:
        gr.Markdown("## SQL ì„œë²„ ë¡œê·¸ì¸")
        with gr.Row():
            with gr.Column(scale=1):
                uid_input = gr.Textbox(label="ID", placeholder="SQL Server ID ì…ë ¥")
            with gr.Column(scale=1):
                pw_input = gr.Textbox(label="Password", type="password", placeholder="SQL Server ë¹„ë°€ë²ˆí˜¸ ì…ë ¥")
        
        with gr.Row():
            login_btn = gr.Button("ë¡œê·¸ì¸", variant="primary")
        
        # ë¡œê·¸ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­
        login_error = gr.Textbox(label="ì˜¤ë¥˜ ë©”ì‹œì§€", visible=False, interactive=False)
    
        # íƒ­ ê¸°ë°˜ ë©”ë‰´ êµ¬ì„±
    with gr.Tabs():
        # ì²« ë²ˆì§¸ íƒ­: ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
        with gr.Tab("ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰"):
            gr.Markdown("ì „ì‹œíšŒ ì´ë¦„ì„ ê²€ìƒ‰í•˜ì—¬ **SQL ì„œë²„**ì—ì„œ í•´ë‹¹ ì „ì‹œíšŒ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
            
            # ê²€ìƒ‰ ì…ë ¥ í¼
            with gr.Row():
                db_search_input = gr.Textbox(label="ì „ì‹œíšŒëª… ê²€ìƒ‰", placeholder="ê²€ìƒ‰í•  ì „ì‹œíšŒ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")
                db_search_btn = gr.Button("DB ê²€ìƒ‰", variant="primary")
            
            # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ì˜ì—­
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼")
                    db_search_output = gr.HTML("ê²€ìƒ‰ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì—¬ê¸°ì— ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            
            # DB ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ìš© ìƒíƒœ ë³€ìˆ˜
            s_db_exhibitions = gr.State()
            
            def check_login_and_db_search(search_term, state):
                """
                ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸ í›„ DB ê²€ìƒ‰ ì‹¤í–‰
                
                Args:
                    search_term (str): ê²€ìƒ‰ì–´
                    state: ë¡œê·¸ì¸ ìƒíƒœ
                    
                Returns:
                    tuple: (ê²°ê³¼ HTML, ê²€ìƒ‰ëœ ì „ì‹œíšŒ ë¦¬ìŠ¤íŠ¸) ë˜ëŠ” (ì˜¤ë¥˜ ë©”ì‹œì§€, None)
                """
                if not state or not state.get("logged_in"):
                    return "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.", None
                if not search_term or not search_term.strip():
                    return "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", None
                try:
                    connection = state.get("connection")
                    # DB ì¡°íšŒ
                    exhibitions = search_exhibition_in_db(search_term.strip(), connection)
                    
                    if not exhibitions:
                        return "<div style='color: var(--body-text-color-subdued); margin-bottom: 10px;'>ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ì „ì‹œíšŒê°€ ì—†ìŠµë‹ˆë‹¤.</div>", None
                    
                    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (ëª¨ë“  ì „ì‹œíšŒ ì •ë³´ í‘œì‹œ)
                    result_html = render_db_table_with_selection(exhibitions)
                    return result_html, exhibitions
                        
                except Exception as e:
                    return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}", None
            
            # DB ê²€ìƒ‰ ë²„íŠ¼ ì´ë²¤íŠ¸ ì—°ê²°
            db_search_btn.click(
                fn=check_login_and_db_search,
                inputs=[db_search_input, login_state],
                outputs=[db_search_output, s_db_exhibitions],
            )
        
        # ë‘ ë²ˆì§¸ íƒ­: ì›¹ ê²€ìƒ‰ ë° ì¶”ì¶œ
        with gr.Tab("ì›¹ ê²€ìƒ‰ ë° ì¶”ì¶œ"):
            gr.Markdown("ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì „ì‹œíšŒë¥¼ ì„ íƒí•˜ë©´ **3ê°œ ì‚¬ì´íŠ¸**ì—ì„œ ìë™ìœ¼ë¡œ ê²€ìƒ‰ ë° **LLM ë°ì´í„° ì¶”ì¶œ**ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
            
            # ì „ì‹œíšŒ ì„ íƒ í¼
            with gr.Row():
                web_search_input = gr.Textbox(label="ì „ì‹œíšŒëª… ê²€ìƒ‰", placeholder="ê²€ìƒ‰í•  ì „ì‹œíšŒ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")
                web_search_btn = gr.Button("DBì—ì„œ ì „ì‹œíšŒ ì°¾ê¸°", variant="primary")
            
            # DB ì „ì‹œíšŒ ì„ íƒ ì˜ì—­
            with gr.Column(visible=False) as db_selection_column:
                gr.Markdown("### ğŸ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì „ì‹œíšŒ ì„ íƒ")
                exhibition_dropdown = gr.Dropdown(
                    label="ì „ì‹œíšŒ ì„ íƒ", 
                    choices=[], 
                    value=None,
                    interactive=True
                )
                
                # ì„ íƒëœ ì „ì‹œíšŒë¡œ 3ì‚¬ì´íŠ¸ ê²€ìƒ‰ ë²„íŠ¼
                db_search_execute_btn = gr.Button("ì„ íƒëœ ì „ì‹œíšŒë¡œ 3ì‚¬ì´íŠ¸ ê²€ìƒ‰", variant="primary", visible=False)
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ì˜ì—­
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ğŸŒ ì›¹ ê²€ìƒ‰ ë° ì¶”ì¶œ ê²°ê³¼")
                    web_search_output = gr.HTML("ì „ì‹œíšŒë¥¼ ì„ íƒí•˜ê³  ì›¹ ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ë©´ ì—¬ê¸°ì— ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
                    
                    # ë“œë¡­ë‹¤ìš´ ì„ íƒ ì˜ì—­ (ì´ˆê¸°ì—ëŠ” ìˆ¨ê¹€)
                    with gr.Column(visible=False) as dropdown_selection_column:
                        gr.Markdown("### ğŸ” ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì „ì‹œíšŒ ì„ íƒ")
                        
                        with gr.Row():
                            with gr.Column():
                                auma_dropdown = gr.Dropdown(
                                    label="AUMA ê²€ìƒ‰ ê²°ê³¼ ì„ íƒ",
                                    choices=["ì„ íƒ ì•ˆí•¨"],
                                    value="ì„ íƒ ì•ˆí•¨",
                                    interactive=True
                                )
                            with gr.Column():
                                gep_dropdown = gr.Dropdown(
                                    label="GEP ê²€ìƒ‰ ê²°ê³¼ ì„ íƒ", 
                                    choices=["ì„ íƒ ì•ˆí•¨"],
                                    value="ì„ íƒ ì•ˆí•¨",
                                    interactive=True
                                )
                            with gr.Column():
                                myfair_dropdown = gr.Dropdown(
                                    label="Myfair ê²€ìƒ‰ ê²°ê³¼ ì„ íƒ",
                                    choices=["ì„ íƒ ì•ˆí•¨"], 
                                    value="ì„ íƒ ì•ˆí•¨",
                                    interactive=True
                                )
                        
                        # ì„ íƒëœ ê²°ê³¼ë¡œ ë°ì´í„° ì¶”ì¶œ ë²„íŠ¼
                        extract_from_selections_btn = gr.Button("ì„ íƒëœ ì „ì‹œíšŒë¡œ ë°ì´í„° ì¶”ì¶œ ì‹¤í–‰", variant="primary", visible=False)
                    
                    # ìµœì¢… ì¶”ì¶œ ê²°ê³¼ í‘œì‹œ ì˜ì—­
                    extraction_results_output = gr.HTML(visible=False)
                    
                    with gr.Row():
                        save_web_btn = gr.Button("ê²°ê³¼ ì—‘ì…€ë¡œ ì €ì¥")
                    file_web = gr.File(label="ì—‘ì…€ íŒŒì¼", interactive=False, file_count="single", file_types=[".xlsx"])
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ìš© ìƒíƒœ ë³€ìˆ˜
            s_web_result = gr.State()
            # ê²€ìƒ‰ëœ ì „ì‹œíšŒ ëª©ë¡ ì €ì¥ìš© ìƒíƒœ ë³€ìˆ˜
            s_web_exhibitions = gr.State()
            # ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° ì €ì¥ìš© ìƒíƒœ ë³€ìˆ˜
            s_search_data = gr.State()
            
            def check_login_and_web_search(search_term, state):
                """
                ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸ í›„ ì›¹ ê²€ìƒ‰ ì‹¤í–‰ (DB ê²°ê³¼ì™€ ìƒê´€ì—†ì´ í•­ìƒ 3ì‚¬ì´íŠ¸ ê²€ìƒ‰)
                
                Args:
                    search_term (str): ê²€ìƒ‰ì–´
                    state: ë¡œê·¸ì¸ ìƒíƒœ
                    
                Returns:
                    tuple: (ê²°ê³¼ HTML, ë“œë¡­ë‹¤ìš´ ì—…ë°ì´íŠ¸ë“¤, ì„ íƒ ì»¬ëŸ¼ ê°€ì‹œì„±, ì¶”ì¶œ ë²„íŠ¼ ê°€ì‹œì„±, ê²€ìƒ‰ ë°ì´í„°)
                """
                if not state or not state.get("logged_in"):
                    return "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.", gr.update(), gr.update(), gr.update(), gr.update(visible=False), gr.update(visible=False), None
                if not search_term or not search_term.strip():
                    return "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", gr.update(), gr.update(), gr.update(), gr.update(visible=False), gr.update(visible=False), None
                try:
                    connection = state.get("connection")
                    # DB ì¡°íšŒ
                    exhibitions = search_exhibition_in_db(search_term.strip(), connection)
                    
                    # DB ì •ë³´ í‘œì‹œ
                    if exhibitions:
                        db_html = render_db_table_with_selection(exhibitions)
                        # DBì— ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°: ì•„ì§ 3ì‚¬ì´íŠ¸ ê²€ìƒ‰ ì•ˆ í•¨ (ì‚¬ìš©ìê°€ DBì—ì„œ ì„ íƒí•´ì•¼ í•¨)
                        results_auma, results_gep, results_myfair = [], [], []
                        
                        # DB ì„ íƒìš© ë“œë¡­ë‹¤ìš´ ì˜µì…˜ ìƒì„±
                        db_choices = []
                        for i, ex in enumerate(exhibitions):
                            korean_name = ex.get('korean_name', '')
                            english_name = ex.get('english_name', '')
                            industry = ex.get('Industry', '')
                            first_host = ex.get('first_host', '')
                            city = extract_city_from_exhibition(ex)
                            
                            display_text = f"{i+1}. {korean_name}"
                            if english_name:
                                display_text += f" ({english_name})"
                            if city:
                                display_text += f" - {city}"
                            if industry:
                                display_text += f" [{industry}]"
                            if first_host and first_host != 'None':
                                display_text += f" (ì‹œì‘: {first_host})"
                            
                            db_choices.append(display_text)
                        
                        # DB ì„ íƒ ì»¬ëŸ¼ í‘œì‹œ
                        return (db_html,
                               gr.update(choices=db_choices, visible=True),
                               gr.update(choices=["ì„ íƒ ì•ˆí•¨"], visible=False),
                               gr.update(choices=["ì„ íƒ ì•ˆí•¨"], visible=False),
                               gr.update(choices=["ì„ íƒ ì•ˆí•¨"], visible=False),
                               gr.update(visible=True),  # DB ì„ íƒ ì»¬ëŸ¼
                               gr.update(visible=False), # ì‚¬ì´íŠ¸ ë“œë¡­ë‹¤ìš´ ì»¬ëŸ¼
                               gr.update(visible=False), # ì¶”ì¶œ ë²„íŠ¼
                               exhibitions,  # DB ê²°ê³¼ë¥¼ s_web_exhibitionsì— ì €ì¥
                               None)  # search_dataëŠ” ì•„ì§ ì—†ìŒ
                    else:
                        db_html = "<div style='color: var(--body-text-color-subdued); margin-bottom: 10px;'>ğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ì „ì‹œíšŒê°€ ì—†ìŠµë‹ˆë‹¤. 3ì‚¬ì´íŠ¸ì—ì„œ ì§ì ‘ ê²€ìƒ‰í•©ë‹ˆë‹¤.</div>"
                        # DBì— ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°: ê²€ìƒ‰ì–´ë¡œ ì§ì ‘ 3ì‚¬ì´íŠ¸ ê²€ìƒ‰
                        print(f"[DB ê²€ìƒ‰ ì‹¤íŒ¨] '{search_term}' ì—†ìŒ. 3ì‚¬ì´íŠ¸ ì§ì ‘ ê²€ìƒ‰ ì‹œì‘...")
                        results_auma = search_auma(search_term)
                        results_gep = search_gep(search_term)
                        results_myfair = search_myfair(search_term)
                        
                        # ë“œë¡­ë‹¤ìš´ ì˜µì…˜ ìƒì„±
                        auma_choices = ["ì„ íƒ ì•ˆí•¨"] + [f"{i+1}. {result['display_text']}" for i, result in enumerate(results_auma)]
                        gep_choices = ["ì„ íƒ ì•ˆí•¨"] + [f"{i+1}. {result['display_text']}" for i, result in enumerate(results_gep)]
                        myfair_choices = ["ì„ íƒ ì•ˆí•¨"] + [f"{i+1}. {result['display_text']}" for i, result in enumerate(results_myfair)]
                        
                        # ë“œë¡­ë‹¤ìš´ HTML ìƒì„±
                        dropdowns_html = render_search_results_dropdowns(results_auma, results_gep, results_myfair)
                        
                        # ì „ì²´ HTML ê²°í•©
                        final_html = db_html + "<hr>" + dropdowns_html
                        
                        # ê²€ìƒ‰ ë°ì´í„° êµ¬ì¡°í™”
                        search_data = {
                            "korean_name": search_term,
                            "english_name": search_term,
                            "AUMA": {},
                            "GEP": {},
                            "Myfair": {},
                            "db_results": [],
                            "search_results": {
                                "auma": results_auma,
                                "gep": results_gep,
                                "myfair": results_myfair
                            }
                        }
                        
                        return (final_html,
                               gr.update(choices=["ì„ íƒ ì•ˆí•¨"], visible=False),
                               gr.update(choices=auma_choices, visible=True),
                               gr.update(choices=gep_choices, visible=True),
                               gr.update(choices=myfair_choices, visible=True),
                               gr.update(visible=False), # DB ì„ íƒ ì»¬ëŸ¼
                               gr.update(visible=True),  # ì‚¬ì´íŠ¸ ë“œë¡­ë‹¤ìš´ ì»¬ëŸ¼
                               gr.update(visible=True),  # ì¶”ì¶œ ë²„íŠ¼
                               [],  # s_web_exhibitionsëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸
                               search_data)
                        
                except Exception as e:
                    return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}", gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(visible=False), gr.update(visible=False), [], None
            
            def execute_db_selection_and_search(db_choice, exhibitions_list, state):
                """
                DBì—ì„œ ì„ íƒëœ ì „ì‹œíšŒë¡œ 3ì‚¬ì´íŠ¸ ê²€ìƒ‰ ì‹¤í–‰
                
                Args:
                    db_choice: DB ë“œë¡­ë‹¤ìš´ ì„ íƒê°’
                    exhibitions_list: DB ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
                    state: ë¡œê·¸ì¸ ìƒíƒœ
                    
                Returns:
                    tuple: (ê²€ìƒ‰ ê²°ê³¼ HTML, ë“œë¡­ë‹¤ìš´ ì—…ë°ì´íŠ¸ë“¤, ì»¬ëŸ¼ ê°€ì‹œì„±, ê²€ìƒ‰ ë°ì´í„°)
                """
                if not state or not state.get("logged_in"):
                    return "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.", gr.update(), gr.update(), gr.update(), gr.update(visible=False), gr.update(visible=False), None
                
                if not db_choice or not exhibitions_list:
                    return "ì„ íƒëœ ì „ì‹œíšŒê°€ ì—†ìŠµë‹ˆë‹¤.", gr.update(), gr.update(), gr.update(), gr.update(visible=False), gr.update(visible=False), None
                
                try:
                    # ì„ íƒëœ í…ìŠ¤íŠ¸ì—ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ
                    import re
                    match = re.match(r'^(\d+)\.', db_choice)
                    if not match:
                        return "ì„ íƒëœ ì „ì‹œíšŒë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", gr.update(), gr.update(), gr.update(), gr.update(visible=False), gr.update(visible=False), None
                    
                    selected_index = int(match.group(1)) - 1
                    selected_exhibition = exhibitions_list[selected_index]
                    korean_name = selected_exhibition['korean_name']
                    english_name = selected_exhibition['english_name']
                    
                    print(f"[ì„ íƒëœ ì „ì‹œíšŒ] '{korean_name}' 3ì‚¬ì´íŠ¸ ê²€ìƒ‰ ì‹œì‘...")
                    results_auma, results_gep, results_myfair = search_three_sites_for_one(korean_name, english_name)
                    
                    # ë“œë¡­ë‹¤ìš´ ì˜µì…˜ ìƒì„±
                    auma_choices = ["ì„ íƒ ì•ˆí•¨"] + [f"{i+1}. {result['display_text']}" for i, result in enumerate(results_auma)]
                    gep_choices = ["ì„ íƒ ì•ˆí•¨"] + [f"{i+1}. {result['display_text']}" for i, result in enumerate(results_gep)]
                    myfair_choices = ["ì„ íƒ ì•ˆí•¨"] + [f"{i+1}. {result['display_text']}" for i, result in enumerate(results_myfair)]
                    
                    # ë“œë¡­ë‹¤ìš´ HTML ìƒì„±
                    dropdowns_html = render_search_results_dropdowns(results_auma, results_gep, results_myfair)
                    
                    # ê²€ìƒ‰ ë°ì´í„° êµ¬ì¡°í™”
                    search_data = {
                        "korean_name": korean_name,
                        "english_name": english_name,
                        "AUMA": {},
                        "GEP": {},
                        "Myfair": {},
                        "db_results": [selected_exhibition],
                        "search_results": {
                            "auma": results_auma,
                            "gep": results_gep,
                            "myfair": results_myfair
                        }
                    }
                    
                    return (dropdowns_html,
                           gr.update(choices=auma_choices, visible=True),
                           gr.update(choices=gep_choices, visible=True),
                           gr.update(choices=myfair_choices, visible=True),
                           gr.update(visible=True),  # ì‚¬ì´íŠ¸ ë“œë¡­ë‹¤ìš´ ì»¬ëŸ¼
                           gr.update(visible=True),  # ì¶”ì¶œ ë²„íŠ¼
                           [selected_exhibition],  # s_web_exhibitions ì—…ë°ì´íŠ¸
                           search_data)
                           
                except Exception as e:
                    return f"3ì‚¬ì´íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}", gr.update(), gr.update(), gr.update(), gr.update(visible=False), gr.update(visible=False), [], None

            def execute_extraction_from_selections(auma_choice, gep_choice, myfair_choice, search_data):
                """
                ë“œë¡­ë‹¤ìš´ì—ì„œ ì„ íƒëœ í•­ëª©ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ ì‹¤í–‰
                
                Args:
                    auma_choice: AUMA ë“œë¡­ë‹¤ìš´ ì„ íƒê°’
                    gep_choice: GEP ë“œë¡­ë‹¤ìš´ ì„ íƒê°’
                    myfair_choice: Myfair ë“œë¡­ë‹¤ìš´ ì„ íƒê°’
                    search_data: ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„°
                    
                Returns:
                    tuple: (ì¶”ì¶œ ê²°ê³¼ HTML, ì—…ë°ì´íŠ¸ëœ ë°ì´í„°)
                """
                if not search_data:
                    return "ê²€ìƒ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", None
                
                try:
                    final_html, result_data = extract_from_selected_choices(
                        auma_choice, gep_choice, myfair_choice, search_data
                    )
                    
                    return final_html, result_data
                    
                except Exception as e:
                    return f"ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}", None
            
            # ì›¹ ê²€ìƒ‰ ë²„íŠ¼ ì´ë²¤íŠ¸ ì—°ê²°
            web_search_btn.click(
                fn=check_login_and_web_search,
                inputs=[web_search_input, login_state],
                outputs=[web_search_output, exhibition_dropdown, auma_dropdown, gep_dropdown, myfair_dropdown, db_selection_column, dropdown_selection_column, extract_from_selections_btn, s_search_data],
            )
            
            # ì „ì‹œíšŒ ì„ íƒ ì‹œ ë²„íŠ¼ í‘œì‹œ ì´ë²¤íŠ¸
            exhibition_dropdown.change(
                fn=lambda choice, exhibitions, state: gr.update(visible=True) if choice and exhibitions and state and state.get("logged_in") else gr.update(visible=False),
                inputs=[exhibition_dropdown, s_web_exhibitions, login_state],
                outputs=[db_search_execute_btn],
            )
            
            # DB ì „ì‹œíšŒ ì„ íƒ í›„ 3ì‚¬ì´íŠ¸ ê²€ìƒ‰ ë²„íŠ¼ ì´ë²¤íŠ¸
            db_search_execute_btn.click(
                fn=execute_db_selection_and_search,
                inputs=[exhibition_dropdown, s_web_exhibitions, login_state],
                outputs=[web_search_output, auma_dropdown, gep_dropdown, myfair_dropdown, dropdown_selection_column, extract_from_selections_btn, s_search_data],
            ).then(
                fn=lambda: gr.update(visible=True),
                outputs=[dropdown_selection_column]
            )
            
            # ì„ íƒëœ ê²°ê³¼ë¡œ ë°ì´í„° ì¶”ì¶œ ë²„íŠ¼ ì´ë²¤íŠ¸
            extract_from_selections_btn.click(
                fn=execute_extraction_from_selections,
                inputs=[auma_dropdown, gep_dropdown, myfair_dropdown, s_search_data],
                outputs=[extraction_results_output, s_web_result],
            ).then(
                fn=lambda: gr.update(visible=True),
                outputs=[extraction_results_output]
            )
            
            # ì—‘ì…€ ì €ì¥ ë²„íŠ¼ ì´ë²¤íŠ¸ ì—°ê²°
            save_web_btn.click(
                fn=lambda data: save_merged_excel([data] if data else [], "web_search_result"),
                inputs=[s_web_result],
                outputs=[file_web]
            )
        


    # ë¡œê·¸ì¸ ë²„íŠ¼ ì´ë²¤íŠ¸ ì—°ê²°
    login_btn.click(
        fn=try_login,
        inputs=[uid_input, pw_input, login_state],
        outputs=[login_section, login_error, login_state]
    ).then(
        # ë¡œê·¸ì¸ ì„±ê³µ ì‹œ UI ìƒíƒœ ì—…ë°ì´íŠ¸
        fn=lambda state: (gr.update(visible=False), gr.update(value="### âœ… ë¡œê·¸ì¸ë˜ì—ˆìŠµë‹ˆë‹¤")) if state and state.get("logged_in") else (gr.update(visible=True), gr.update()),
        inputs=[login_state],
        outputs=[login_section, login_status]
    )

if __name__ == "__main__":
    demo.launch(server_name="127.0.0.1", server_port=7869)
